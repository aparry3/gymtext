# Chat Interface Implementation Guide

## Implementation Phases

### Phase 1: Basic Chat Experience with Streaming
Focus: Create a working chat interface with streaming responses

### Phase 2: Profile Building Tools
Focus: Add LangChain tools for data extraction and profile saving

### Phase 3: Production Ready
Focus: Polish, error handling, and optimization

---

## Phase 1: Basic Chat Experience

### 1.1 Frontend Setup

#### Task 1.1.1: Create Chat Page Structure
- [x] Create `/app/chat/page.tsx`
- [x] Set up basic page layout with centered container
- [x] Add metadata and page title
- [x] Implement responsive design constraints

#### Task 1.1.2: Build Initial State UI
- [x] Create centered input box component
- [x] Add "What are your fitness goals?" placeholder
- [x] Style to match ChatGPT/Claude aesthetic
- [x] Add focus states and animations

#### Task 1.1.3: Create Chat Components
- [x] Create `/app/chat/components/ChatInterface.tsx`
  - [x] Manage chat state (messages, loading, error)
  - [x] Handle initial â†’ active state transition
- [x] Create `/app/chat/components/MessageList.tsx`
  - [x] Display message history
  - [x] Auto-scroll to bottom on new messages
  - [x] Handle empty state
- [x] Create `/app/chat/components/Message.tsx`
  - [x] User message styling (right-aligned)
  - [x] Assistant message styling (left-aligned)
  - [x] Timestamp display
- [x] Create `/app/chat/components/MessageInput.tsx`
  - [x] Text input with auto-resize
  - [x] Send button
  - [x] Enter key handling
  - [x] Disabled state during processing
- [x] Create `/app/chat/components/StreamingMessage.tsx`
  - [x] Display partial message content
  - [x] Typing indicator animation
  - [x] Smooth content updates

#### Task 1.1.4: Implement State Management
- [x] Set up local state for messages array
- [x] Implement message addition logic
- [x] Handle streaming message updates
- [x] Add loading and error states

### 1.2 Backend Infrastructure

#### Task 1.2.1: Create Onboarding Agent
- [x] Create `/server/agents/onboarding/chain.ts`
- [x] Set up LLM with streaming support
- [x] Create initial system prompt for fitness onboarding
- [x] Implement basic conversation chain
- [x] Add context management for conversation history
- [x] Test streaming output

#### Task 1.2.2: Create Chat Interface Service
- [x] Create `/server/services/chatInterfaceService.ts`
- [x] Implement `startConversation()` method
- [x] Implement `sendMessage()` method with streaming
- [x] Add session management
- [x] Integrate with onboarding agent
- [x] Handle errors gracefully

#### Task 1.2.3: Create API Route
- [x] Create `/app/api/chat/route.ts`
- [x] Implement POST handler with streaming response
- [x] Set up proper headers for SSE/streaming
- [x] Add request validation
- [x] Implement error handling
- [x] Test with curl/Postman

### 1.3 Frontend-Backend Integration

#### Task 1.3.1: Implement API Client
- [x] Create fetch wrapper for chat API
- [x] Handle streaming responses (ReadableStream)
- [x] Parse SSE or stream chunks
- [x] Implement error handling
- [x] Add retry logic

#### Task 1.3.2: Connect UI to API
- [x] Wire up message sending
- [x] Implement streaming message display
- [x] Handle connection errors
- [x] Add loading states
- [x] Test end-to-end flow

### 1.4 Testing & Validation

#### Task 1.4.1: Component Testing
- [ ] Test MessageInput component
- [ ] Test Message component rendering
- [ ] Test StreamingMessage updates
- [ ] Test ChatInterface state transitions

#### Task 1.4.2: Integration Testing
- [ ] Test API route with mock agent
- [ ] Test service with mock agent
- [ ] Test full chat flow
- [ ] Test error scenarios

#### Task 1.4.3: Manual Testing Checklist
- [ ] Chat loads with centered input
- [ ] First message transitions to chat view
- [ ] Messages display correctly (user/assistant)
- [ ] Streaming works smoothly
- [ ] Enter key sends message
- [ ] Error messages display properly
- [ ] Mobile responsive design works

---

## Phase 2: Profile Building Tools

### 2.1 Tool Development

#### Task 2.1.1: Create Profile Extraction Tools
- [ ] Create LangChain tool for user data extraction
- [ ] Create tool for fitness profile extraction
- [ ] Implement data validation in tools
- [ ] Add structured output parsing

#### Task 2.1.2: Integrate Repository Methods
- [ ] Add tool to save user via UserRepository
- [ ] Add tool to save fitness profile via FitnessProfileRepository
- [ ] Implement transaction handling
- [ ] Add conflict resolution

### 2.2 Agent Enhancement

#### Task 2.2.1: Enhance Onboarding Agent
- [ ] Add tools to agent chain
- [ ] Implement progressive information gathering
- [ ] Add validation prompts
- [ ] Create completion detection logic
- [ ] Add profile summary generation

#### Task 2.2.2: Improve Prompts
- [ ] Refine system prompt for better extraction
- [ ] Add examples for edge cases
- [ ] Implement follow-up question logic
- [ ] Add confirmation flows

### 2.3 Service Layer Updates

#### Task 2.3.1: Add Profile Management
- [ ] Implement profile completion tracking
- [ ] Add profile validation logic
- [ ] Create profile summary endpoint
- [ ] Handle partial profile saves

#### Task 2.3.2: Session Persistence
- [ ] Save conversations to database
- [ ] Implement conversation resumption
- [ ] Add conversation cleanup
- [ ] Handle user authentication

### 2.4 UI Enhancements

#### Task 2.4.1: Add Profile Progress
- [ ] Create progress indicator component
- [ ] Show completed fields
- [ ] Add field validation feedback
- [ ] Implement profile preview

#### Task 2.4.2: Improve UX
- [ ] Add suggested responses
- [ ] Implement quick actions
- [ ] Add conversation reset option
- [ ] Create help tooltips

---

## Phase 3: Production Ready

### 3.1 Performance Optimization

#### Task 3.1.1: Frontend Optimization
- [ ] Implement message virtualization for long conversations
- [ ] Add message pagination
- [ ] Optimize re-renders
- [ ] Add response caching
- [ ] Implement lazy loading

#### Task 3.1.2: Backend Optimization
- [ ] Add response caching
- [ ] Implement rate limiting
- [ ] Optimize LLM token usage
- [ ] Add request queuing
- [ ] Implement connection pooling

### 3.2 Error Handling & Recovery

#### Task 3.2.1: Comprehensive Error Handling
- [ ] Add network error recovery
- [ ] Implement stream reconnection
- [ ] Add fallback responses
- [ ] Create error boundaries
- [ ] Add error logging

#### Task 3.2.2: User Feedback
- [ ] Add connection status indicator
- [ ] Implement retry mechanisms with UI feedback
- [ ] Create helpful error messages
- [ ] Add troubleshooting guide

### 3.3 Security & Compliance

#### Task 3.3.1: Security Measures
- [ ] Implement input sanitization
- [ ] Add content filtering
- [ ] Implement CSRF protection
- [ ] Add rate limiting per user
- [ ] Audit logging

#### Task 3.3.2: Data Privacy
- [ ] Add conversation encryption
- [ ] Implement data retention policies
- [ ] Add user consent flows
- [ ] Create privacy controls

### 3.4 Analytics & Monitoring

#### Task 3.4.1: Add Analytics
- [ ] Track conversation metrics
- [ ] Monitor completion rates
- [ ] Track error rates
- [ ] Add performance monitoring
- [ ] Implement A/B testing framework

#### Task 3.4.2: Debugging Tools
- [ ] Add conversation export
- [ ] Create admin view
- [ ] Add debug mode
- [ ] Implement replay functionality

---

## Definition of Done Checklist

### For Each Component
- [ ] TypeScript types defined
- [ ] Component renders correctly
- [ ] Responsive design implemented
- [ ] Accessibility standards met (ARIA labels, keyboard nav)
- [ ] Unit tests written and passing
- [ ] No console errors or warnings

### For Each API Endpoint
- [ ] Request validation implemented
- [ ] Error handling complete
- [ ] TypeScript types defined
- [ ] Rate limiting configured
- [ ] Tests written and passing
- [ ] Documentation updated

### For Each Service Method
- [ ] Business logic implemented
- [ ] Error handling complete
- [ ] TypeScript types defined
- [ ] Unit tests written
- [ ] Integration tests written
- [ ] Performance acceptable

### For Each Agent
- [ ] Prompts optimized
- [ ] Streaming implemented
- [ ] Error handling complete
- [ ] Token usage optimized
- [ ] Tests with mock LLM
- [ ] Manual testing completed

---

## Testing Strategy

### Unit Tests
```bash
pnpm test                  # Run all tests
pnpm test:ui              # Run with UI
pnpm test chat            # Run chat-specific tests
```

### Manual Testing Scenarios
1. **Happy Path**
   - Start new conversation
   - Complete full profile
   - Verify data saved correctly

2. **Error Recovery**
   - Disconnect during streaming
   - Send invalid input
   - API timeout scenarios

3. **Edge Cases**
   - Very long messages
   - Rapid message sending
   - Multiple browser tabs
   - Mobile device testing

### Integration Testing
- Test with actual LLM (not mocked)
- Test database persistence
- Test full onboarding flow
- Test profile extraction accuracy

---

## Code Quality Checklist

### Before Each Commit
- [ ] Run `pnpm lint` - no errors
- [ ] Run `pnpm build` - builds successfully
- [ ] Run `pnpm test` - all tests pass
- [ ] TypeScript types complete
- [ ] No TODO comments without tickets

### Before Phase Completion
- [ ] Code review completed
- [ ] Documentation updated
- [ ] Performance benchmarked
- [ ] Security review done
- [ ] Accessibility tested

---

## Risk Mitigation Log

### Technical Risks
| Risk | Impact | Mitigation | Status |
|------|--------|------------|--------|
| Streaming API complexity | High | Research implementations, use established patterns | Pending |
| LLM response latency | Medium | Implement caching, optimize prompts | Pending |
| Profile extraction accuracy | High | Iterative prompt improvement, validation | Pending |
| Session management | Medium | Use established patterns, add tests | Pending |

### UX Risks
| Risk | Impact | Mitigation | Status |
|------|--------|------------|--------|
| Mobile experience poor | High | Mobile-first development | Pending |
| Conversation gets too long | Medium | Add summarization, pagination | Pending |
| User confusion | Medium | Add help text, examples | Pending |

---

## Progress Tracking

### Phase 1 Progress
- [x] Frontend Setup (4/4 tasks)
- [x] Backend Infrastructure (3/3 tasks)
- [x] Integration (2/2 tasks)
- [ ] Testing (0/3 tasks)
- **Overall Phase 1**: 75%

### Phase 2 Progress
- [ ] Tool Development (0/2 tasks)
- [ ] Agent Enhancement (0/2 tasks)
- [ ] Service Updates (0/2 tasks)
- [ ] UI Enhancements (0/2 tasks)
- **Overall Phase 2**: 0%

### Phase 3 Progress
- [ ] Performance (0/2 tasks)
- [ ] Error Handling (0/2 tasks)
- [ ] Security (0/2 tasks)
- [ ] Analytics (0/2 tasks)
- **Overall Phase 3**: 0%

---

## Notes and Decisions

### Architecture Decisions
- Using streaming API for real-time responses
- Session-based storage initially, then DB persistence
- Agent pattern for all LLM interactions
- Repository pattern for data access

### Technology Choices
- Streaming: Server-Sent Events or ReadableStream
- State Management: Local state initially, consider Zustand later
- Testing: Vitest for unit/integration tests
- LLM Provider: Use existing Gemini/OpenAI infrastructure

### Open Questions
- [ ] Authentication integration approach?
- [ ] How to handle existing SMS users?
- [ ] Rate limiting strategy?
- [ ] Conversation history retention period?

---

## Commands Reference

```bash
# Development
pnpm dev                 # Start development server

# Testing
pnpm test               # Run tests
pnpm test:ui            # Run tests with UI
pnpm test chat          # Run chat-specific tests

# Database (if needed for Phase 2)
pnpm db:codegen         # Update types after schema changes
pnpm migrate:create     # Create new migration
pnpm migrate:up         # Apply migrations

# Code Quality
pnpm lint               # Run linter
pnpm build              # Build for production
```